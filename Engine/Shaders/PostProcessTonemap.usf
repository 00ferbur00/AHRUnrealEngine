// Copyright 1998-2014 Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	PostProcessTonemap.usf: PostProcessing tone mapping
=============================================================================*/

#include "Common.usf"
#include "PostProcessCommon.usf"
#include "TonemapCommon.usf"

#include "BRDF.usf"
#include "MonteCarlo.usf"

//
// 64x64 tiling noise texture, optimized to have mostly high frequency content
Texture2D NoiseTexture;
SamplerState NoiseTextureSampler;

// xyz:SceneColorTint.rgb, w:unused
float4 ColorScale0;
// xyz:Bloom1Tint.rgb, w:unused
float4 ColorScale1;

// to scale UV (with border) to NormaizedUV (without border)
float2 TexScale;

// from the postprocess settings
float4 VignetteColorIntensity;

// Fine film grain
float3 GrainRandomFull;
float3 GrainScaleBiasJitter;

half GrainFromUV(float2 GrainUV) 
{
	half Grain = frac(sin(GrainUV.x + GrainUV.y * 543.31) *  493013.0);
	return Grain;
}

half3 LinearToSrgbBranchless(half3 lin) 
{
	lin = max(6.10352e-5, lin); // minimum positive non-denormal (fixes black problem on DX11 AMD and NV)
	return min(lin * 12.92, pow(max(lin, 0.00313067), 1.0/2.4) * 1.055 - 0.055);
	// Possible that mobile GPUs might have native pow() function?
	//return min(lin * 12.92, exp2(log2(max(lin, 0.00313067)) * (1.0/2.4) + log2(1.055)) - 0.055);
}

half LinearToSrgbBranchingChannel(half lin) 
{
	if(lin < 0.00313067) return lin * 12.92;
	return pow(lin, (1.0/2.4)) * 1.055 - 0.055;
}

half3 LinearToSrgbBranching(half3 lin) 
{
	return half3(
		LinearToSrgbBranchingChannel(lin.r),
		LinearToSrgbBranchingChannel(lin.g),
		LinearToSrgbBranchingChannel(lin.b));
}



// 256x16 color LUT for color grading
#if USE_VOLUME_LUT == 1
	Texture3D ColorGradingLUT;
	SamplerState ColorGradingLUTSampler;
#endif

//  @param InLDRColor in gamma space, has to be in 0..1 range
half3 ColorLookupTable(half3 InLDRColor)
{
#if USE_VOLUME_LUT == 1
	return Texture3DSample(ColorGradingLUT, ColorGradingLUTSampler, InLDRColor * (15.0f / 16.0f) + (0.5f / 16.0f)).xyz;
#else
	// requires a volume texture 16x16x16 unwrapped in a 2d texture 256x16
	// can be optimized by using a volume texture
	float2 Offset = float2(0.5f / 256.0f, 0.5f / 16.0f);
	float Scale = 15.0f / 16.0f; 

	// Also consider blur value in the blur buffer written by translucency
	float IntB = floor(InLDRColor.b * 14.9999f) / 16.0f;
	half FracB = InLDRColor.b * 15.0f - IntB * 16.0f;

	float U = IntB + InLDRColor.r * Scale / 16.0f;
	float V = InLDRColor.g * Scale;

	half3 RG0 = Texture2DSample(PostprocessInput3, PostprocessInput3Sampler, Offset + float2(U             , V)).rgb;
	half3 RG1 = Texture2DSample(PostprocessInput3, PostprocessInput3Sampler, Offset + float2(U + 1.0f / 16.0f, V)).rgb;

	return lerp(RG0, RG1, FracB);
#endif
}

// xy should be a integer position (e.g. pixel position on the screen)
// use the PseudoRandom() function if you have ALU performance left
// and this if you have TEX performance left.
float PseudoRandomTex(float2 xy)
{
	return Texture2DSample(NoiseTexture, NoiseTextureSampler, xy / 64.0f).r;
}

float SwitchVerticalAxis;



// can be optimized
float2 ScreenPosToUV(float2 ScreenPos)
{
	return (ScreenPos * ScreenPosToPixel.xy + ScreenPosToPixel.zw) * PostprocessInput0Size.zw;
}

float2 UVToScreenPos(float2 UV)
{
	return (UV * PostprocessInput0Size.xy - ScreenPosToPixel.zw) / ScreenPosToPixel.xy;
}

float4 FringeUVParams;

// vertex shader entry point
void MainVS(
	in float4 InPosition : ATTRIBUTE0,
	in float2 InTexCoord : ATTRIBUTE1,
	out float4 OutTexCoord : TEXCOORD0,
	out float3 OutExposureScaleVignette : TEXCOORD1,
	out float4 OutGrainUV : TEXCOORD2,
	out float4 OutFringe : TEXCOORD3,
	out float4 OutPosition : SV_POSITION
	)
{
	DrawRectangle(InPosition, InTexCoord, OutPosition, OutTexCoord.xy);
	OutTexCoord = float4(OutTexCoord.xy, OutPosition.xy);

#if FEATURE_LEVEL >= FEATURE_LEVEL_SM5
	// texture can be GWhiteTexture which is 1x1. It's important we don't read outside bounds.
	OutExposureScaleVignette.x = EyeAdaptation.Load(int3(0, 0, 0)).r;
#else
	// Eye adaptation is not yet supported
	OutExposureScaleVignette.x = 1.0f;
#endif

	// Scale vignette to always be a circle with consistent corner intensity.
	OutExposureScaleVignette.yz = VignetteSpace(OutTexCoord.zw);

	// Grain
	OutGrainUV.xy = OutTexCoord.xy + PostprocessInput0Size.zw * float2(-0.5,0.5);
	OutGrainUV.zw = OutTexCoord.xy + GrainRandomFull.xy;

	// Fringe
	float2 ScreenPos = UVToScreenPos(OutTexCoord.xy);
	OutFringe.xy = ScreenPosToUV(ScreenPos * FringeUVParams.r);
	OutFringe.zw = ScreenPosToUV(ScreenPos * FringeUVParams.g);
}



float2 IntegrateBRDF( uint2 Random, float Roughness, float NoV )
{
	float F0 = 0.04;
	float Fc = pow( 1 - NoV, 5 );
	float F = Fc + (1 - Fc) * F0;

	float3 V;
	V.x = sqrt( 1.0f - NoV * NoV );	// sin
	V.y = 0;
	V.z = NoV;						// cos

	float A = 0;
	float B = 0;

	const uint NumSamples = 16;
	for( uint i = 0; i < NumSamples; i++ )
	{
		float2 E = Hammersley( i, NumSamples, Random );
		float3 H = ImportanceSampleGGX( E, Roughness ).xyz;
		float3 L = 2 * dot( V, H ) * H - V;

		float NoL = saturate( L.z );
		float NoH = saturate( H.z );
		float VoH = saturate( dot( V, H ) );

		if( NoL > 0 )
		{
			float Vis = Vis_Schlick( Roughness, NoV, NoL );

			// Incident light = NoL
			// pdf = D * NoH / (4 * VoH)
			// NoL * Vis / pdf
			float NoL_Vis_PDF = NoL * Vis * (4 * VoH / NoH);
			NoL_Vis_PDF *= (1 - F);

			float Fc = pow( 1 - VoH, 5 );
			A += (1 - Fc) * NoL_Vis_PDF;
			B += Fc * NoL_Vis_PDF;
		}
	}

	return float2( A, B ) / NumSamples;
}

float2 IntegrateClearCoat( uint2 Random, float Roughness, float NoV )
{
	float3 V;
	V.x = sqrt( 1.0f - NoV * NoV );	// sin
	V.y = 0;
	V.z = NoV;						// cos

	float A = 0;
	float B = 0;

	const uint NumSamples = 16;
	for( uint i = 0; i < NumSamples; i++ )
	{
		float2 E = Hammersley( i, NumSamples, Random );
		float3 H = ImportanceSampleGGX( E, Roughness ).xyz;
		float3 L = 2 * dot( V, H ) * H - V;

		float NoL = saturate( L.z );
		float NoH = saturate( H.z );
		float VoH = saturate( dot( V, H ) );

		float RefractBlend = (0.22 * VoH + 0.7) * VoH + 0.745;
		float RefractNoH = RefractBlend * NoH;
		float NoL2 = saturate( RefractNoH - (1 / 1.5) * NoL );
		float NoV2 = saturate( RefractNoH - (1 / 1.5) * NoV );

		if( NoL > 0 )
		{
			float Vis = Vis_Schlick( Roughness, NoV2, NoL2 );

			float NoL_Vis_PDF = NoL * Vis * (4 * VoH / NoH);

			float Fc = pow( 1 - VoH, 5 );
			A += (1 - Fc) * NoL_Vis_PDF;
			B += Fc * NoL_Vis_PDF;
		}
	}

	float F0 = 0.04;
	float Fc = pow( 1 - NoV, 5 );
	float F = Fc + (1 - Fc) * F0;

	return (1 - Fc) * float2( A, B ) / NumSamples;
}

float G_Schlick( float Roughness, float NoV, float NoL )
{
	float k = Square( Roughness ) * 0.5;
	float Vis_SchlickV = NoV * (1 - k) + k;
	float Vis_SchlickL = NoL * (1 - k) + k;
	return ( NoV * NoL ) / ( 4 * Vis_SchlickV * Vis_SchlickL );
}

float IntegrateAbsorption( uint2 Random, float Roughness, float NoV, float AbsorptionColor )
{
	float3 V;
	V.x = sqrt( 1.0f - NoV * NoV );	// sin
	V.y = 0;
	V.z = NoV;						// cos

	float A = 0;
	float B = 0;

	const uint NumSamples = 16;
	for( uint i = 0; i < NumSamples; i++ )
	{
		float2 E = Hammersley( i, NumSamples, Random );
		float3 H = ImportanceSampleGGX( E, Roughness ).xyz;
		float3 L = 2 * dot( V, H ) * H - V;

		float NoL = saturate( L.z );
		float NoH = saturate( H.z );
		float VoH = saturate( dot( V, H ) );

		if( NoL > 0 )
		{
			float3 L2 = refract( -L, -H, 1 / 1.5 );
			float3 V2 = refract( -V, -H, 1 / 1.5 );
			float3 H2 = normalize(V2 + L2);

			float NoL2 = saturate( L2.z );
			float NoV2 = saturate( V2.z );
			float NoH2 = saturate( H2.z );
			float VoH2 = saturate( dot(V2, H2) );
			
			float AbsorptionDist = rcp(NoV2) + rcp(NoL2);
			float Absorption = pow( AbsorptionColor, 0.5 * AbsorptionDist );

			float F21 = 0.04 + 0.96 * ClampedPow( 1 - saturate( dot(V2, H) ), 5 );
			float TotalInternalReflection = 1 - F21 * G_Schlick( Roughness, NoV2, NoL2 );
			float3 LayerAttenuation = TotalInternalReflection * Absorption;

			float D = D_GGX( Roughness, NoH2 );
			float Vis = Vis_Schlick( Roughness, NoV2, NoL2 );

			float PDF = D_GGX( Roughness, NoH2 ) * NoH / (4 * VoH);

			float NoL_Vis_PDF = NoL * Vis * D / PDF;

			NoL_Vis_PDF *= LayerAttenuation;

			float Fc = pow( 1 - VoH2, 5 );
			A += (1 - Fc) * NoL_Vis_PDF;
			B += Fc * NoL_Vis_PDF;
		}
	}

	float F0 = 0.04;
	float Fc = pow( 1 - NoV, 5 );
	float F = Fc + (1 - Fc) * F0;

	return (1 - F) * float2( A, B ) / NumSamples;
}

float ApproxAbsorption( float Roughness, float NoV, float AbsorptionColor )
{
	float Toe = 1 - exp2( -9 * NoV - 3.5 );
	return Toe * AbsorptionColor * ( (NoV - 1) * 0.85 * ( 1 - lerp( AbsorptionColor, Square(AbsorptionColor), -0.78 ) ) + lerp( 0.93, 0.96, AbsorptionColor * 2 - 1 ) );
}

// Function graphing
float F0( float x )
{
	//return x*saturate( (x - 0.5)/2 );
	//return IntegrateBRDF( uint2(0,0), 0.75, x ).x;
	return IntegrateAbsorption( uint2(0,0), 0.4, x, 0.85 ) / ( IntegrateClearCoat( uint2(0,0), 0.4, x ).x );
}

float F1( float x )
{
	return IntegrateAbsorption( uint2(0,0), 0.4, x, 0.5 ) / ( IntegrateClearCoat( uint2(0,0), 0.4, x ).x );
	//return IntegrateAbsorption( uint2(0,0), 0, x );
}

float F2( float x )
{
	//return x;
	return IntegrateAbsorption( uint2(0,0), 0.4, x, 0.25 ) / ( IntegrateClearCoat( uint2(0,0), 0.4, x ).x );

	float Roughness = 0.5;
	float NoV = x;

	float F0 = 0.04;
	float Fc = pow( 1 - NoV, 5 );
	float F = Fc + (1 - Fc) * F0;

	// [ Lazarov 2013, "Getting More Physical in Call of Duty: Black Ops II" ]
	// Adaptation to fit our G term.
	half a004 = min( Square(1 - Roughness), exp2( -9.28 * NoV ) ) * (1 - Roughness) + Roughness * -0.0275 + 0.0425;
	half AB = 1.04 * (1 - a004) + Roughness * -0.572;

	AB = IntegrateBRDF( uint2(0,0), Roughness, x ).x;

	//AB *= (1 - F);

	float Scale = saturate( (NoV - 1) * lerp( 1.3, 0.5, Roughness ) + 1 );
	//float Scale = 0.85;

	return AB * Scale;
}

float F3( float x )
{
	//return x;
	return IntegrateAbsorption( uint2(0,0), 0.4, x, 0.05 ) / ( IntegrateClearCoat( uint2(0,0), 0.4, x ).x );
}

float F4( float x )
{
	return ApproxAbsorption( 0.4, x, 0.85 );
	//return (x - 1) * 0.12 + 0.95;
}

float F5( float x )
{
	//return (x - 1) * 0.25 + 0.93;

	return ApproxAbsorption( 0.4, x, 0.5 );
}

float F6( float x )
{
	return ApproxAbsorption( 0.4, x, 0.25 );
	//return (x - 1) * 0.45 + 0.9;
}

float F7( float x )
{
	return ApproxAbsorption( 0.4, x, 0.05 );
	//return (x - 1) * 0.7 + 0.82;
}

float LineShade( float fx, float y, float dydx, float LineWidth )
{
	return 1 - smoothstep( 0.5 * LineWidth, LineWidth, abs( fx - y ) / sqrt( 1 + Square( dydx ) ) );
}

float3 Graph( float2 ScreenSpacePos )
{
	float2 WindowMin = float2( 0, 0 );
	float2 WindowMax = float2( 1, 1 );
	
	float2 p = ( (ScreenSpacePos + 1) * 0.5 - WindowMin ) * ( WindowMax - WindowMin );
	float LineWidth = dot( WindowMax - WindowMin, 0.0005 );
	
	float3 Color;
	Color  = float3( 1, 0, 0 ) * LineShade( F0(p.x), p.y, ( F0(p.x + LineWidth) - F0(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 0, 1, 0 ) * LineShade( F1(p.x), p.y, ( F1(p.x + LineWidth) - F1(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 0, 0, 1 ) * LineShade( F2(p.x), p.y, ( F2(p.x + LineWidth) - F2(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 1, 1, 0 ) * LineShade( F3(p.x), p.y, ( F3(p.x + LineWidth) - F3(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );

	Color += float3( 1, 0.5, 0 ) * LineShade( F4(p.x), p.y, ( F4(p.x + LineWidth) - F4(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 0, 1, 1 ) * LineShade( F5(p.x), p.y, ( F5(p.x + LineWidth) - F5(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 1, 0, 1 ) * LineShade( F6(p.x), p.y, ( F6(p.x + LineWidth) - F6(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	Color += float3( 1, 1, 1 ) * LineShade( F7(p.x), p.y, ( F7(p.x + LineWidth) - F7(p.x - LineWidth) ) / (2 * LineWidth), LineWidth );
	
	return Color;
}

// pixel shader entry point
void MainPS(
	in float4 UVAndScreenPos : TEXCOORD0,
	in float3 InExposureScaleVignette : TEXCOORD1,
	in float4 GrainUV : TEXCOORD2,
	in float4 FringeUV : TEXCOORD3,
	out float4 OutColor : SV_Target0
	)
{
	float2 UV = UVAndScreenPos.xy;
	float2 ScreenSpacePos = UVAndScreenPos.zw;

	#if USE_GRAIN_JITTER || USE_GRAIN_INTENSITY || USE_GRAIN_QUANTIZATION
		half Grain = GrainFromUV(GrainUV.zw);
	#endif

	float2 SceneUV = UV.xy;
	#if USE_GRAIN_JITTER
		SceneUV = lerp(UV.xy, GrainUV.xy, (1.0 - Grain*Grain) * GrainScaleBiasJitter.z);
	#endif

	#if USE_COLOR_FRINGE
		float2 SceneUVJitter = float2(0.0, 0.0);
		#if USE_GRAIN_JITTER
			SceneUVJitter = SceneUV.xy - UV.xy;
		#endif
		half4 SceneColor = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, SceneUV);
		half SceneColorG = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, FringeUV.xy + SceneUVJitter.xy).g;
		half SceneColorB = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, FringeUV.zw + SceneUVJitter.xy).b;
		SceneColor.g = SceneColorG;
		SceneColor.b = SceneColorB;
	#else
		half4 SceneColor = Texture2DSample(PostprocessInput0, PostprocessInput0Sampler, SceneUV);
	#endif

	#if USE_GAMMA_ONLY

		OutColor = pow(SceneColor, InverseGamma.x);

	#else 

		half3 LinearColor = SceneColor.rgb * ColorScale0.rgb;

		#if USE_BLOOM
			float4 CombinedBloom = Texture2DSample(PostprocessInput1, PostprocessInput1Sampler, UV);
			float3 BloomDirtMaskColor = Texture2DSample(BloomDirtMask.Mask, BloomDirtMask.MaskSampler, ScreenSpacePos * float2(0.5, -0.5f) + 0.5f).rgb * BloomDirtMask.Tint.rgb; 
			LinearColor += CombinedBloom.rgb * (ColorScale1.rgb + BloomDirtMaskColor); 
		#endif

		float ExposureScale = InExposureScaleVignette.x;

		#if NO_EYEADAPTATION_EXPOSURE_FIX
			ExposureScale = BloomDirtMask.Tint.w;
		#endif

		LinearColor *= ExposureScale;

		#if USE_VIGNETTE
			#if USE_VIGNETTE_COLOR 
				LinearColor.rgb = lerp(VignetteColorIntensity.rgb, LinearColor.rgb, ComputeVignetteMask(InExposureScaleVignette.yz, VignetteColorIntensity.a));
			#else
				LinearColor.rgb *= ComputeVignetteMask(InExposureScaleVignette.yz, VignetteColorIntensity.a);
			#endif
		#endif

		#if USE_GRAIN_INTENSITY
			// Needs to go before tonemapping.
			half GrainMul = Grain * GrainScaleBiasJitter.x + GrainScaleBiasJitter.y;
			LinearColor.rgb *= GrainMul;
		#endif

		half3 FilmColor = FilmPostProcess(LinearColor.rgb);
		
		// Apply "gamma" curve adjustment.
		FilmColor.rgb = pow(FilmColor.rgb, InverseGamma.y);
		
		#if MAC
			// Note, MacOSX native output is raw gamma 2.2 not sRGB!
			half3 TonemappedColor = pow(FilmColor.rgb, 1.0/2.2);
		#else
			// Apply conversion to sRGB (this must be an exact sRGB conversion else darks are bad).
			// Branching is faster than branchless on AMD on PC.
			half3 TonemappedColor = LinearToSrgbBranching(FilmColor);
		#endif

		//TonemappedColor = rsqrt( ( 0.8 + 0.8 * LinearColor ) / LinearColor );		// 1 vmad, 3 rcp, 1 vmul, 3 rsqrt
		//TonemappedColor = sqrt( 1 - exp( -LinearColor ) );						// 1 vmul, 3 exp2, 1 vadd, 3 sqrt
		//TonemappedColor = ( LinearColor * (3.85 * LinearColor + 0.128) ) / ( LinearColor * (3.74 * LinearColor + 1.14) + 0.02 );	// 3 rcp, 3 vmads, 2 vmuls
		//TonemappedColor = pow( TonemappedColor, 2.0 / 2.2 );

		//TonemappedColor = Graph( ScreenSpacePos );
		float Roughness = 0;//UV.x;
		float NoV = UV.y;
		//TonemappedColor.xy = IntegrateClearCoat( uint2(0,0), Roughness, NoV ).x / IntegrateBRDF( uint2(0,0), Roughness, NoV ).x;
		//TonemappedColor.z = 0;
	
		half LuminanceForPostProcessAA  = dot(TonemappedColor, half3(0.299f, 0.587f, 0.114f));

		#if USE_GRAIN_QUANTIZATION
			// Needs to go after tonemapping.
			half GrainQuantization = 1.0/256.0;
			half GrainAdd = (Grain * GrainQuantization) + (-0.5 * GrainQuantization);
			TonemappedColor.rgb += GrainAdd;
		#endif

		// apply color grading
		TonemappedColor = ColorLookupTable(TonemappedColor);

		// RETURN_COLOR not needed unless writing to SceneColor
		OutColor = float4(TonemappedColor, LuminanceForPostProcessAA);
	#endif
}


// ES2 version

// TODO: Convert float to half.

// vertex shader entry point
void MainVS_ES2(
	in float4 InPosition : ATTRIBUTE0,
	in float2 InTexCoord : ATTRIBUTE1,
	out float4 OutTexCoord : TEXCOORD0,
	out float4 OutFineDofGrain : TEXCOORD1,
	out float4 OutFullViewUV : TEXCOORD2,
	out float2 OutVignette : TEXCOORD3,
	out float2 OutTexCoords[4] : TEXCOORD4,
	out float4 OutPosition : SV_POSITION
	)
{
	DrawRectangle(InPosition, InTexCoord, OutPosition, OutTexCoord.xy);
	OutTexCoord = float4(OutTexCoord.xy, OutPosition.xy);

	// Avoiding a permutation.
	if(GrainRandomFull.z > 0.0)
	{
		// Framebuffer fetch hardware uses the standard possibly non-full rectangle.
		// Other hardware gets a full texture source.
		OutTexCoord.xy = OutPosition.xy * float2(0.5,-0.5) + 0.5;
	}

	#if ES2_PROFILE && COMPILER_GLSL_ES2
		// This is currently the last pass, so flip the texture on V to match D3D
		OutTexCoord.y = 1.0 - OutTexCoord.y;
	#endif

	// Fine adjustment is inside the possible non-full viewport in the full resolution texture.
	OutFineDofGrain.xy = OutTexCoord.xy + PostprocessInput0Size.zw * float2(-0.5,0.5);
	// Want grain and a second UV based on the knowledge that the source texture has a full viewport.
	OutFullViewUV.xy = OutPosition.xy * float2(0.5,-0.5) + 0.5;
	#if ES2_PROFILE && COMPILER_GLSL_ES2
		// This is currently the last pass, so flip the texture on V to match D3D
		OutFullViewUV.y = 1.0 - OutFullViewUV.y;
	#endif
	// For DOF attempt to undo sampling bias for the first transition region.
	// This is better for the fine transition, breaks down for the larger bokeh.
	// This is the best compromise for mobile using 4 bilinear taps only.
	OutFullViewUV.zw = OutFullViewUV.xy + PostprocessInput2Size.zw * float2(0.25,-0.5);
	OutFineDofGrain.zw = OutFullViewUV.xy + GrainRandomFull.xy;
	// NEWS
	OutTexCoords[0] = OutTexCoord.xy + PostprocessInput0Size.zw * float2( 0,-1);
	OutTexCoords[1] = OutTexCoord.xy + PostprocessInput0Size.zw * float2( 1, 0);
	OutTexCoords[2] = OutTexCoord.xy + PostprocessInput0Size.zw * float2(-1, 0);
	OutTexCoords[3] = OutTexCoord.xy + PostprocessInput0Size.zw * float2( 0, 1);

	// Scale vignette to always be a circle with consistent corner intensity.
	OutVignette.xy = VignetteSpace(InPosition.xy);
}

// Constants for DOF blend in.
half CocMaxRadiusInPixelsRcp() 
{ 
	half2 MaxOffset = half2(-2.125,-0.50)*2.0; 
	return rcp(sqrt(dot(MaxOffset, MaxOffset))); 
}

half2 CocBlendScaleBias() 
{
	half2 Start = 0.25 * CocMaxRadiusInPixelsRcp();
	half2 End = 1.0 * CocMaxRadiusInPixelsRcp();
	half2 ScaleBias;
	ScaleBias.x = 1.0/(End-Start);
	ScaleBias.y = (-Start)*ScaleBias.x;
	return ScaleBias;
}

half2 CocBlendScaleBiasFine() 
{
	half2 Start = 0.0 * CocMaxRadiusInPixelsRcp();
	half2 End = 0.5 * CocMaxRadiusInPixelsRcp();
	half2 ScaleBias;
	ScaleBias.x = 1.0/(End-Start);
	ScaleBias.y = (-Start)*ScaleBias.x;
	return ScaleBias;
}

float4 OverlayColor;

void MainPS_ES2(
	in float4 UVAndScreenPos : TEXCOORD0,
	in float4 FineDofGrain : TEXCOORD1,
	in float4 FullViewUV : TEXCOORD2,
	in float2 InVignette : TEXCOORD3,
	in float2 InTexCoords[4] : TEXCOORD4,
	#if USE_HDR_MOSAIC
		in float4 SvPosition : SV_Position,
	#endif
	out half4 OutColor : SV_Target0
	)
{
	float2 UV = UVAndScreenPos.xy;
	float2 ScreenSpacePos = UVAndScreenPos.zw;

	half4 SceneColor = PostprocessInput0.Sample(PostprocessInput0Sampler, UV);

	#if USE_GAMMA_ONLY
		OutColor.rgb = sqrt(SceneColor.rgb);
	#else

		#if USE_GRAIN_JITTER || USE_GRAIN_INTENSITY || USE_GRAIN_QUANTIZATION
			half Grain = GrainFromUV(FineDofGrain.zw);
		#endif

		#if USE_DOF
			half4 DofFine = PostprocessInput0.Sample(PostprocessInput0Sampler, FineDofGrain.xy);
			half4 Dof = PostprocessInput2.Sample(PostprocessInput2Sampler, FullViewUV.zw);
			// Convert alpha back into circle of confusion.
			SceneColor.a = max(Dof.a, abs(SceneColor.a * 2.0 - 1.0));
			// Convert circle of confusion into blend factors.		
			half2 ScaleBias = CocBlendScaleBias(); // Constant.
			half DofAmount = saturate(SceneColor.a * ScaleBias.x + ScaleBias.y);
			half2 ScaleBias2 = CocBlendScaleBiasFine(); // Constant.
			half DofAmountFine = saturate(SceneColor.a * ScaleBias2.x + ScaleBias2.y);
			#if USE_GRAIN_JITTER
				// Grain can increase fine DOF.
				DofAmountFine = max((1.0-Grain*Grain) * GrainScaleBiasJitter.z, DofAmountFine);
			#endif
			// Blend in fine DOF.
			SceneColor.rgb = lerp(SceneColor.rgb, DofFine.rgb, DofAmountFine);
			// Blend in coarse DOF.
			SceneColor.rgb = lerp(SceneColor.rgb, Dof.rgb, DofAmount);
		#else
			// Set so temporal AA shader knows everything is in focus.
			SceneColor.a = 0.0;
			#if USE_GRAIN_JITTER
				#if USE_HDR_MOSAIC
					// This has grain jitter off.
				#else
					// Do jitter for grain.
					half4 DofFine = PostprocessInput0.Sample(PostprocessInput0Sampler, FineDofGrain.xy);
					// Grain jitter.
					SceneColor.rgb = lerp(SceneColor.rgb, DofFine.rgb, (1.0-Grain*Grain) * GrainScaleBiasJitter.z);
				#endif
			#endif
		#endif

		#if USE_HDR_MOSAIC
			// TODO: Support odd frame inversion of mosaic pattern?
			#if 0
				half3 SceneColorE = PostprocessInput0.Sample(PostprocessInput0Sampler, InTexCoords[1].xy).rgb;
				SceneColor.rgb = HdrDemosaic(SceneColor.rgb, SceneColorE, SvPosition.xy);
			#endif
			#if 1
				// Higher quality path.
				half3 SceneColorN = PostprocessInput0.Sample(PostprocessInput0Sampler, InTexCoords[0].xy).rgb;
				half3 SceneColorE = PostprocessInput0.Sample(PostprocessInput0Sampler, InTexCoords[1].xy).rgb;
				half3 SceneColorW = PostprocessInput0.Sample(PostprocessInput0Sampler, InTexCoords[2].xy).rgb;
				half3 SceneColorS = PostprocessInput0.Sample(PostprocessInput0Sampler, InTexCoords[3].xy).rgb;
				half3 SceneColorV = SceneColorN * 0.5 + SceneColorS * 0.5;
				half3 SceneColorH = SceneColorW * 0.5 + SceneColorE * 0.5;
				if(abs(SceneColorN.g - SceneColorS.g) < abs(SceneColorW.g - SceneColorE.g)) 
				{
					SceneColorH = SceneColorV;
				}
				SceneColor.rgb = HdrDemosaic(SceneColor.rgb, SceneColorH, SvPosition.xy);
			#endif
		#endif

		// Match PC naming.
		half3 LinearColor = SceneColor.rgb;

		#if USE_HDR_MOSAIC
			#if USE_VIGNETTE
				#if USE_VIGNETTE_COLOR 
					LinearColor.rgb = lerp(VignetteColorIntensity.rgb, LinearColor.rgb, ComputeVignetteMask(InVignette.xy, VignetteColorIntensity.a));
				#else
					LinearColor.rgb *= ComputeVignetteMask(InVignette.xy, VignetteColorIntensity.a);
				#endif
			#endif
		#endif

		// It is faster to do vignette as a texture lookup + mad because this is an ALU bound shader.
		#if (!USE_HDR_MOSAIC) && (USE_BLOOM || USE_LIGHT_SHAFTS || USE_VIGNETTE || USE_VIGNETTE_COLOR)
			half4 CombinedBloomSunVignette = Texture2DSample(PostprocessInput1, PostprocessInput1Sampler, FullViewUV.xy);
			LinearColor.rgb = LinearColor.rgb * CombinedBloomSunVignette.a + CombinedBloomSunVignette.rgb;
		#endif

		#if USE_GRAIN_INTENSITY
			// Needs to go before tonemapping.
			half GrainMul = Grain * GrainScaleBiasJitter.x + GrainScaleBiasJitter.y;
			LinearColor.rgb *= GrainMul;
		#endif

		half3 FilmColor = FilmPostProcess(LinearColor.rgb);
		#if IOS
			// Note, iOS native output is raw gamma 2.2 not sRGB!
			half3 TonemappedColor = pow(FilmColor.rgb, 1.0/2.2);
		#else
			// Apply conversion to sRGB (this must be an exact sRGB conversion else darks are bad).
			half3 TonemappedColor = LinearToSrgbBranchless(FilmColor);
		#endif

		// Blend with custom LDR color, used for Fade track in Matinee.
		// This is the 101% wrong way to do this,
		//  - It adds an extra redundant lerp.
		//  - It is not going to work with the future-forward ES3 fast path of sRGB output.
		//  - And it does super ugly non-linear blending.
		// The right way is to adjust exposure instead.
		TonemappedColor = lerp(TonemappedColor.rgb, OverlayColor.rgb, OverlayColor.a);

		#if USE_GRAIN_QUANTIZATION
			// Needs to go after tonemapping.
			half GrainQuantization = 1.0/256.0;
			half GrainAdd = (Grain * GrainQuantization) + (-0.5 * GrainQuantization);
			TonemappedColor.rgb += GrainAdd;
		#endif
			
		OutColor = half4(TonemappedColor, SceneColor.a);

	#endif
}
